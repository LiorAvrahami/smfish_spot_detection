{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import itertools\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from regions_of_interest_module.regions_of_interest import find_points_of_interest\n",
    "from image_manipulation.crop_image_for_classifier import crop, is_valid_size\n",
    "from image_loader.Image2numpy import convert_image_file_to_numpy\n",
    "from image_manipulation.standardize_image import normalize_image\n",
    "\n",
    "# now comes the neural network\n",
    "from noise_reduction.model_denoise import DenoiseNet\n",
    "from spot_classifier_NN.classifier_model import spots_classifier_net as ClassifierNet\n",
    "\n",
    "from image_loader.load_tagged_image import load_tagged_image\n",
    "from create_training_data.training_data_generator import TaggedImagesGenerator\n",
    "\n",
    "NUM_OF_ROI_IN_BATCH = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_cleaner_network = DenoiseNet()\n",
    "image_cleaner_network.load_state_dict(torch.load('denoiseNet.pt', map_location=torch.device('cpu')))\n",
    "\n",
    "classifier_network = ClassifierNet()\n",
    "classifier_network.load_state_dict(torch.load(\"classifyNet.pt\", map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_image(image: npt.NDArray) -> npt.NDArray:\n",
    "    image = torch.tensor(image)  # type: ignore\n",
    "    image = image.permute(3, 2, 1, 0)  # get ch,z,x,y # type: ignore\n",
    "    image_real = image.unsqueeze(1)  # type: ignore\n",
    "    pred = image_cleaner_network(image_real.float()).detach()\n",
    "    pred = pred[:, 0, :, :, :]\n",
    "    pred = pred.permute(3, 2, 1, 0)\n",
    "    return pred.numpy()\n",
    "\n",
    "def classify_roi_list(small_images_list: npt.NDArray, cutoff=0.95):\n",
    "    images = torch.tensor(small_images_list)  # type: ignore\n",
    "    images = images.permute(0, 4, 3, 2, 1)  # get ch,z,x,y # type: ignore\n",
    "    pred = classifier_network(images.float()).detach()\n",
    "    pred = torch.sigmoid(pred)\n",
    "    has_point = pred.numpy() > cutoff\n",
    "    result_channel = np.zeros(has_point.shape)\n",
    "    return has_point, result_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "for i in range(1,7):\n",
    "    fig,axes = plt.subplots(2,3,figsize=(23,15))\n",
    "    axes = iter(axes.flatten())\n",
    "    \n",
    "    ogimage, tags = load_tagged_image(f\"images\\\\tagged_images_validation\\\\img{i}\")\n",
    "\n",
    "    image = normalize_image(ogimage)\n",
    "    image = image[..., :3]\n",
    "    image = clean_image(image)\n",
    "\n",
    "    points_of_interest = list(zip(*np.where(find_points_of_interest(image))))  # type: ignore\n",
    "    points_of_interest: list[tuple[int, int, int]]  # points_of_interest = list of (x,y,z) points\n",
    "\n",
    "    # prepare a batch of small images\n",
    "    small_images_arr = []\n",
    "    small_images_center_location_arr = []\n",
    "    for point in points_of_interest:\n",
    "        small_image = crop(ogimage, point[0], point[1])\n",
    "        if not is_valid_size(small_image):\n",
    "            continue\n",
    "        small_images_arr.append(small_image)\n",
    "        small_images_center_location_arr.append(point)\n",
    "    small_images_arr = np.array(small_images_arr)\n",
    "    small_images_center_location_arr = np.array(small_images_center_location_arr)\n",
    "    \n",
    "    for cutoff in [0.5,0.7,0.85,0.9,0.95,0.985]:\n",
    "        \n",
    "        small_images_arr_copy = np.copy(small_images_arr)\n",
    "        has_point_list, result_channels_list = classify_roi_list(small_images_arr_copy, cutoff)\n",
    "        \n",
    "        ch = int(tags[-1][3])\n",
    "        ax = next(axes)\n",
    "        ax.imshow(np.max(ogimage[...,ch],axis=-1),cmap=\"gray\")\n",
    "        ax.plot(tags[:,0],tags[:,1],\".g\",markersize=3)\n",
    "        ax.plot(small_images_center_location_arr[has_point_list,1],small_images_center_location_arr[has_point_list,0],\".r\",markersize=1)\n",
    "        ax.set_title(f\"image:{i}, cutoff:{cutoff}, shown_channel:{ch}\")\n",
    "    fig.savefig(os.path.join(\"result_images\",f\"im{i}.tiff\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TaggedImagesGenerator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8280\\2733223261.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimage_gen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTaggedImagesGenerator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_default_training_data_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TaggedImagesGenerator' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_gen = TaggedImagesGenerator.make_default_training_data_generator(batch_size=1)\n",
    "\n",
    "for i in range(1,7):\n",
    "    fig,axes = plt.subplots(2,3,figsize=(23,15))\n",
    "    axes = iter(axes.flatten())\n",
    "    ogimage, tags = image_gen.get_next_batch()[0]\n",
    "    \n",
    "    image = normalize_image(ogimage)\n",
    "    image = image[..., :3]\n",
    "    image = clean_image(image)\n",
    "\n",
    "    points_of_interest = list(zip(*np.where(find_points_of_interest(image))))  # type: ignore\n",
    "    points_of_interest: list[tuple[int, int, int]]  # points_of_interest = list of (x,y,z) points\n",
    "\n",
    "    # prepare a batch of small images\n",
    "    small_images_arr = []\n",
    "    small_images_center_location_arr = []\n",
    "    for point in points_of_interest:\n",
    "        small_image = crop(ogimage, point[0], point[1])\n",
    "        if not is_valid_size(small_image):\n",
    "            continue\n",
    "        small_images_arr.append(small_image)\n",
    "        small_images_center_location_arr.append(point)\n",
    "    small_images_arr = np.array(small_images_arr)\n",
    "    small_images_center_location_arr = np.array(small_images_center_location_arr)\n",
    "    \n",
    "    for cutoff in [0.5,0.7,0.85,0.9,0.95,0.985]:\n",
    "        \n",
    "        small_images_arr_copy = np.copy(small_images_arr)\n",
    "        has_point_list, result_channels_list = classify_roi_list(small_images_arr_copy, cutoff)\n",
    "        \n",
    "        ch = int(tags[-1][-1])\n",
    "        ax = next(axes)\n",
    "        ax.imshow(np.max(ogimage[...,ch],axis=-1),cmap=\"gray\")\n",
    "        ax.plot(tags[:,0],tags[:,1],\".g\",markersize=3)\n",
    "        ax.plot(small_images_center_location_arr[has_point_list,1],small_images_center_location_arr[has_point_list,0],\".r\",markersize=1)\n",
    "        ax.set_title(f\"image:{i}, cutoff:{cutoff}, shown_channel:{ch}\")\n",
    "    fig.savefig(os.path.join(\"result_images\",f\"synth_im{i}.tiff\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
