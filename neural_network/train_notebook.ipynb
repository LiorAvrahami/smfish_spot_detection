{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "has cuda: True\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as func\n",
    "from tqdm.notebook import tqdm\n",
    "from PIL import Image\n",
    "import gc\n",
    "import torch.optim as optim\n",
    "import pickle\n",
    "import datetime \n",
    "\n",
    "import os,sys\n",
    "try:\n",
    "    import this_is_root\n",
    "except:\n",
    "    os.chdir(os.path.pardir) # change workdir to be root dir\n",
    "    sys.path.insert(0, os.path.realpath(\".\"))\n",
    "\n",
    "import create_training_data.training_data_generator\n",
    "import neural_network.train_classifier as tc\n",
    "torch.cuda.is_available()\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU!\n",
      "Pickle file: run_statistics_spot_detection_lr-0.001_seed-410single_lior.pickle\n",
      "Epoch:  0 ( 0.00 %) Train loss:  0.6934121251106262  Valid loss:  0.6900181174278259\n",
      "Epoch:  3 ( 0.00 %) Train loss:  0.6957538723945618  Valid loss:  0.6955972909927368\n",
      "Epoch:  6 ( 0.00 %) Train loss:  0.6948292851448059  Valid loss:  0.6942368745803833\n",
      "Epoch:  9 ( 0.00 %) Train loss:  0.6955453753471375  Valid loss:  0.693133533000946\n",
      "Epoch:  12 ( 0.00 %) Train loss:  0.6940143704414368  Valid loss:  0.693541407585144\n",
      "Epoch:  15 ( 0.00 %) Train loss:  0.6935548186302185  Valid loss:  0.6928088068962097\n",
      "Epoch:  18 ( 0.00 %) Train loss:  0.6934188008308411  Valid loss:  0.693488597869873\n",
      "Epoch:  21 ( 0.00 %) Train loss:  0.6931284070014954  Valid loss:  0.6935717463493347\n",
      "Epoch:  24 ( 0.00 %) Train loss:  0.693228006362915  Valid loss:  0.6935160160064697\n",
      "Epoch:  27 ( 0.00 %) Train loss:  0.6939811110496521  Valid loss:  0.6933470964431763\n",
      "Epoch:  30 ( 0.00 %) Train loss:  0.6931843757629395  Valid loss:  0.6933093667030334\n",
      "Epoch:  33 ( 0.00 %) Train loss:  0.6933441758155823  Valid loss:  0.6939935088157654\n",
      "Epoch:  36 ( 0.00 %) Train loss:  0.6931577324867249  Valid loss:  0.694331169128418\n",
      "Epoch:  39 ( 0.00 %) Train loss:  0.6933434009552002  Valid loss:  0.6941150426864624\n",
      "Epoch:  42 ( 0.00 %) Train loss:  0.6933369040489197  Valid loss:  0.6939039826393127\n",
      "Epoch:  45 ( 0.00 %) Train loss:  0.6931314468383789  Valid loss:  0.6927303075790405\n",
      "Epoch:  48 ( 0.00 %) Train loss:  0.6931971907615662  Valid loss:  0.6965789794921875\n",
      "Epoch:  51 ( 0.01 %) Train loss:  0.6932507157325745  Valid loss:  0.6945538520812988\n",
      "Epoch:  54 ( 0.01 %) Train loss:  0.693096935749054  Valid loss:  0.6936978697776794\n",
      "Epoch:  57 ( 0.01 %) Train loss:  0.6931644082069397  Valid loss:  0.6938821077346802\n",
      "Epoch:  60 ( 0.01 %) Train loss:  0.6931429505348206  Valid loss:  0.6943379044532776\n",
      "Epoch:  63 ( 0.01 %) Train loss:  0.6930825114250183  Valid loss:  0.69349205493927\n",
      "Epoch:  66 ( 0.01 %) Train loss:  0.6931542754173279  Valid loss:  0.6940169334411621\n",
      "Epoch:  69 ( 0.01 %) Train loss:  0.693226158618927  Valid loss:  0.6945365071296692\n",
      "Epoch:  72 ( 0.01 %) Train loss:  0.6931602954864502  Valid loss:  0.6935275793075562\n",
      "Epoch:  75 ( 0.01 %) Train loss:  0.6934916973114014  Valid loss:  0.6931853294372559\n",
      "Epoch:  78 ( 0.01 %) Train loss:  0.6931785941123962  Valid loss:  0.6938544511795044\n",
      "Epoch:  81 ( 0.01 %) Train loss:  0.6931854486465454  Valid loss:  0.6938413977622986\n",
      "Epoch:  84 ( 0.01 %) Train loss:  0.6930011510848999  Valid loss:  0.6947100162506104\n",
      "Epoch:  87 ( 0.01 %) Train loss:  0.6929987668991089  Valid loss:  0.6948532462120056\n",
      "Epoch:  90 ( 0.01 %) Train loss:  0.6929824948310852  Valid loss:  0.6936104893684387\n",
      "Epoch:  93 ( 0.01 %) Train loss:  0.6925224661827087  Valid loss:  0.6942459344863892\n",
      "Epoch:  96 ( 0.01 %) Train loss:  0.6911333203315735  Valid loss:  0.6941121816635132\n",
      "Epoch:  99 ( 0.01 %) Train loss:  0.6859578490257263  Valid loss:  0.6958645582199097\n",
      "Epoch:  102 ( 0.01 %) Train loss:  0.6724503636360168  Valid loss:  0.6913352012634277\n",
      "Epoch:  105 ( 0.01 %) Train loss:  0.7030044794082642  Valid loss:  0.6986907124519348\n",
      "Epoch:  108 ( 0.01 %) Train loss:  0.681847333908081  Valid loss:  0.6922838687896729\n",
      "Epoch:  111 ( 0.01 %) Train loss:  0.6563702821731567  Valid loss:  0.742231547832489\n",
      "Epoch:  114 ( 0.01 %) Train loss:  0.6508191823959351  Valid loss:  0.6681098937988281\n",
      "Epoch:  117 ( 0.01 %) Train loss:  0.6094619631767273  Valid loss:  0.651394248008728\n",
      "Epoch:  120 ( 0.01 %) Train loss:  0.6253335475921631  Valid loss:  0.7398707270622253\n",
      "Epoch:  123 ( 0.01 %) Train loss:  0.6079204082489014  Valid loss:  0.659498929977417\n",
      "Epoch:  126 ( 0.01 %) Train loss:  0.5637062788009644  Valid loss:  0.68019038438797\n",
      "Epoch:  129 ( 0.01 %) Train loss:  0.5632178783416748  Valid loss:  0.6919019818305969\n",
      "Epoch:  132 ( 0.01 %) Train loss:  0.5476899147033691  Valid loss:  0.6876072883605957\n",
      "Epoch:  135 ( 0.01 %) Train loss:  0.5566344857215881  Valid loss:  0.693974494934082\n",
      "Epoch:  138 ( 0.01 %) Train loss:  0.5183635354042053  Valid loss:  0.6883489489555359\n",
      "Epoch:  141 ( 0.01 %) Train loss:  0.5112192630767822  Valid loss:  0.6928836107254028\n",
      "Epoch:  144 ( 0.01 %) Train loss:  0.5083634257316589  Valid loss:  0.7109588384628296\n",
      "Epoch:  147 ( 0.01 %) Train loss:  0.5024492740631104  Valid loss:  0.6991199851036072\n",
      "Epoch:  150 ( 0.01 %) Train loss:  0.4707278907299042  Valid loss:  0.6933377981185913\n",
      "Epoch:  153 ( 0.02 %) Train loss:  0.49810269474983215  Valid loss:  0.695772111415863\n",
      "Epoch:  156 ( 0.02 %) Train loss:  0.49961522221565247  Valid loss:  0.6867462396621704\n",
      "Epoch:  159 ( 0.02 %) Train loss:  0.47036978602409363  Valid loss:  0.6753931641578674\n",
      "Epoch:  162 ( 0.02 %) Train loss:  0.47973933815956116  Valid loss:  0.6479053497314453\n",
      "Epoch:  165 ( 0.02 %) Train loss:  0.45707762241363525  Valid loss:  0.6549596190452576\n",
      "Epoch:  168 ( 0.02 %) Train loss:  0.460159569978714  Valid loss:  0.6764686107635498\n",
      "Epoch:  171 ( 0.02 %) Train loss:  0.478628009557724  Valid loss:  0.6779232621192932\n",
      "Epoch:  174 ( 0.02 %) Train loss:  0.4756821095943451  Valid loss:  0.6529653668403625\n",
      "Epoch:  177 ( 0.02 %) Train loss:  0.4628731310367584  Valid loss:  0.7011470198631287\n",
      "Epoch:  180 ( 0.02 %) Train loss:  0.482526034116745  Valid loss:  0.6284729838371277\n",
      "Epoch:  183 ( 0.02 %) Train loss:  0.48513057827949524  Valid loss:  0.6513800024986267\n",
      "Epoch:  186 ( 0.02 %) Train loss:  0.49590617418289185  Valid loss:  0.6718529462814331\n",
      "Epoch:  189 ( 0.02 %) Train loss:  0.44352826476097107  Valid loss:  0.6870890855789185\n",
      "Epoch:  192 ( 0.02 %) Train loss:  0.4543159008026123  Valid loss:  0.6922101974487305\n",
      "Epoch:  195 ( 0.02 %) Train loss:  0.4621904790401459  Valid loss:  0.6698545813560486\n",
      "Epoch:  198 ( 0.02 %) Train loss:  0.4579828977584839  Valid loss:  0.6490874290466309\n",
      "Epoch:  201 ( 0.02 %) Train loss:  0.41195401549339294  Valid loss:  0.6301189064979553\n",
      "Epoch:  204 ( 0.02 %) Train loss:  0.4211294651031494  Valid loss:  0.6223790049552917\n",
      "Epoch:  207 ( 0.02 %) Train loss:  0.4090390205383301  Valid loss:  0.6170475482940674\n",
      "Epoch:  210 ( 0.02 %) Train loss:  0.40517985820770264  Valid loss:  0.5948610305786133\n",
      "Epoch:  213 ( 0.02 %) Train loss:  0.40895092487335205  Valid loss:  0.6163069009780884\n",
      "Epoch:  216 ( 0.02 %) Train loss:  0.3944358825683594  Valid loss:  0.6100953817367554\n",
      "Epoch:  219 ( 0.02 %) Train loss:  0.3985535800457001  Valid loss:  0.6238757371902466\n",
      "Epoch:  222 ( 0.02 %) Train loss:  0.3922975957393646  Valid loss:  0.6137957572937012\n",
      "Epoch:  225 ( 0.02 %) Train loss:  0.3637700080871582  Valid loss:  0.6470308899879456\n",
      "Epoch:  228 ( 0.02 %) Train loss:  0.40290892124176025  Valid loss:  0.5589941143989563\n",
      "Epoch:  231 ( 0.02 %) Train loss:  0.39479860663414  Valid loss:  0.6269481182098389\n",
      "Epoch:  234 ( 0.02 %) Train loss:  0.38693392276763916  Valid loss:  0.6731972098350525\n",
      "Epoch:  237 ( 0.02 %) Train loss:  0.352774053812027  Valid loss:  0.6998796463012695\n",
      "Epoch:  240 ( 0.02 %) Train loss:  0.3661355674266815  Valid loss:  0.6471226215362549\n",
      "Epoch:  243 ( 0.02 %) Train loss:  0.350957989692688  Valid loss:  0.6045523285865784\n",
      "Epoch:  246 ( 0.02 %) Train loss:  0.345639169216156  Valid loss:  0.6292815208435059\n",
      "Epoch:  249 ( 0.02 %) Train loss:  0.3801800012588501  Valid loss:  0.6487649083137512\n",
      "Epoch:  252 ( 0.03 %) Train loss:  0.34145164489746094  Valid loss:  0.6207586526870728\n",
      "Epoch:  255 ( 0.03 %) Train loss:  0.3267812728881836  Valid loss:  0.6384701728820801\n",
      "Epoch:  258 ( 0.03 %) Train loss:  0.36155223846435547  Valid loss:  0.6227540373802185\n",
      "Epoch:  261 ( 0.03 %) Train loss:  0.36821070313453674  Valid loss:  0.5818433165550232\n",
      "Epoch:  264 ( 0.03 %) Train loss:  0.3310970962047577  Valid loss:  0.6221056580543518\n",
      "Epoch:  267 ( 0.03 %) Train loss:  0.36671268939971924  Valid loss:  0.5368775129318237\n",
      "Epoch:  270 ( 0.03 %) Train loss:  0.31116437911987305  Valid loss:  0.6104556322097778\n",
      "Epoch:  273 ( 0.03 %) Train loss:  0.38098156452178955  Valid loss:  0.6056204438209534\n",
      "Epoch:  276 ( 0.03 %) Train loss:  0.3829869031906128  Valid loss:  0.5646635293960571\n",
      "Epoch:  279 ( 0.03 %) Train loss:  0.35046979784965515  Valid loss:  0.6283798813819885\n",
      "Epoch:  282 ( 0.03 %) Train loss:  0.3443163335323334  Valid loss:  0.5705784559249878\n",
      "Epoch:  285 ( 0.03 %) Train loss:  0.3506395220756531  Valid loss:  0.5921692252159119\n",
      "Epoch:  288 ( 0.03 %) Train loss:  0.3447039723396301  Valid loss:  0.5488641262054443\n",
      "Epoch:  291 ( 0.03 %) Train loss:  0.3103456199169159  Valid loss:  0.520068883895874\n",
      "Epoch:  294 ( 0.03 %) Train loss:  0.34891170263290405  Valid loss:  0.5454903244972229\n",
      "Epoch:  297 ( 0.03 %) Train loss:  0.3018473982810974  Valid loss:  0.5358967781066895\n",
      "Epoch:  300 ( 0.03 %) Train loss:  0.3883214592933655  Valid loss:  0.5287458300590515\n",
      "Epoch:  303 ( 0.03 %) Train loss:  0.3187965750694275  Valid loss:  0.5169779658317566\n",
      "Epoch:  306 ( 0.03 %) Train loss:  0.36942464113235474  Valid loss:  0.5498563051223755\n",
      "Epoch:  309 ( 0.03 %) Train loss:  0.32554957270622253  Valid loss:  0.5179765224456787\n",
      "Epoch:  312 ( 0.03 %) Train loss:  0.3580540716648102  Valid loss:  0.5187366604804993\n",
      "Epoch:  315 ( 0.03 %) Train loss:  0.3322919011116028  Valid loss:  0.5343053936958313\n",
      "Epoch:  318 ( 0.03 %) Train loss:  0.29175499081611633  Valid loss:  0.5500410199165344\n",
      "Epoch:  321 ( 0.03 %) Train loss:  0.32484304904937744  Valid loss:  0.5295699238777161\n",
      "Epoch:  324 ( 0.03 %) Train loss:  0.3425971567630768  Valid loss:  0.5218073129653931\n",
      "Epoch:  327 ( 0.03 %) Train loss:  0.31537026166915894  Valid loss:  0.5043949484825134\n",
      "Epoch:  330 ( 0.03 %) Train loss:  0.3126455545425415  Valid loss:  0.536351203918457\n",
      "Epoch:  333 ( 0.03 %) Train loss:  0.3302878439426422  Valid loss:  0.5398539900779724\n",
      "Epoch:  336 ( 0.03 %) Train loss:  0.3349279463291168  Valid loss:  0.5061832666397095\n",
      "Epoch:  339 ( 0.03 %) Train loss:  0.32898715138435364  Valid loss:  0.4991818964481354\n",
      "Epoch:  342 ( 0.03 %) Train loss:  0.3258562982082367  Valid loss:  0.5238602757453918\n",
      "Epoch:  345 ( 0.03 %) Train loss:  0.33352556824684143  Valid loss:  0.5181381702423096\n",
      "Epoch:  348 ( 0.03 %) Train loss:  0.3247009813785553  Valid loss:  0.5285250544548035\n",
      "Epoch:  351 ( 0.04 %) Train loss:  0.3121688961982727  Valid loss:  0.5132507085800171\n",
      "Epoch:  354 ( 0.04 %) Train loss:  0.32998043298721313  Valid loss:  0.49540868401527405\n",
      "Epoch:  357 ( 0.04 %) Train loss:  0.28618115186691284  Valid loss:  0.48692670464515686\n",
      "Epoch:  360 ( 0.04 %) Train loss:  0.3546437919139862  Valid loss:  0.5067074298858643\n",
      "Epoch:  363 ( 0.04 %) Train loss:  0.31477710604667664  Valid loss:  0.4886433482170105\n",
      "Epoch:  366 ( 0.04 %) Train loss:  0.27218955755233765  Valid loss:  0.48323920369148254\n",
      "Epoch:  369 ( 0.04 %) Train loss:  0.2788918912410736  Valid loss:  0.5499608516693115\n",
      "Epoch:  372 ( 0.04 %) Train loss:  0.3017168641090393  Valid loss:  0.52194744348526\n",
      "Epoch:  375 ( 0.04 %) Train loss:  0.31718993186950684  Valid loss:  0.5017969608306885\n",
      "Epoch:  378 ( 0.04 %) Train loss:  0.284596711397171  Valid loss:  0.5055528283119202\n",
      "Epoch:  381 ( 0.04 %) Train loss:  0.28105220198631287  Valid loss:  0.5172211527824402\n",
      "Epoch:  384 ( 0.04 %) Train loss:  0.29735276103019714  Valid loss:  0.5140505433082581\n",
      "Epoch:  387 ( 0.04 %) Train loss:  0.30631881952285767  Valid loss:  0.5355725884437561\n",
      "Epoch:  390 ( 0.04 %) Train loss:  0.31506985425949097  Valid loss:  0.47964712977409363\n",
      "Epoch:  393 ( 0.04 %) Train loss:  0.30978453159332275  Valid loss:  0.48985400795936584\n",
      "Epoch:  396 ( 0.04 %) Train loss:  0.298006147146225  Valid loss:  0.46823203563690186\n",
      "Epoch:  399 ( 0.04 %) Train loss:  0.28783825039863586  Valid loss:  0.44468367099761963\n",
      "Epoch:  402 ( 0.04 %) Train loss:  0.2840987741947174  Valid loss:  0.4603903293609619\n",
      "Epoch:  405 ( 0.04 %) Train loss:  0.29860350489616394  Valid loss:  0.4735465347766876\n",
      "Epoch:  408 ( 0.04 %) Train loss:  0.34623095393180847  Valid loss:  0.49916499853134155\n",
      "Epoch:  411 ( 0.04 %) Train loss:  0.28704121708869934  Valid loss:  0.4675416648387909\n",
      "Epoch:  414 ( 0.04 %) Train loss:  0.3314143419265747  Valid loss:  0.48945990204811096\n",
      "Epoch:  417 ( 0.04 %) Train loss:  0.3280095160007477  Valid loss:  0.5108251571655273\n",
      "Epoch:  420 ( 0.04 %) Train loss:  0.3315858542919159  Valid loss:  0.5071014761924744\n",
      "Epoch:  423 ( 0.04 %) Train loss:  0.2955462634563446  Valid loss:  0.4878963232040405\n",
      "Epoch:  426 ( 0.04 %) Train loss:  0.3273754417896271  Valid loss:  0.4968416094779968\n",
      "Epoch:  429 ( 0.04 %) Train loss:  0.30472198128700256  Valid loss:  0.48528289794921875\n",
      "Epoch:  432 ( 0.04 %) Train loss:  0.3166230320930481  Valid loss:  0.4824637472629547\n",
      "Epoch:  435 ( 0.04 %) Train loss:  0.2923579216003418  Valid loss:  0.49061480164527893\n",
      "Epoch:  438 ( 0.04 %) Train loss:  0.2858416736125946  Valid loss:  0.4824565649032593\n",
      "Epoch:  441 ( 0.04 %) Train loss:  0.27470892667770386  Valid loss:  0.49825984239578247\n",
      "Epoch:  444 ( 0.04 %) Train loss:  0.2920759320259094  Valid loss:  0.49810466170310974\n",
      "Epoch:  447 ( 0.04 %) Train loss:  0.32654136419296265  Valid loss:  0.5543468594551086\n",
      "Epoch:  450 ( 0.04 %) Train loss:  0.28094547986984253  Valid loss:  0.4798131585121155\n",
      "Epoch:  453 ( 0.05 %) Train loss:  0.27886536717414856  Valid loss:  0.43431511521339417\n",
      "Epoch:  456 ( 0.05 %) Train loss:  0.29230621457099915  Valid loss:  0.4833354949951172\n",
      "Epoch:  459 ( 0.05 %) Train loss:  0.26252633333206177  Valid loss:  0.4774046838283539\n",
      "Epoch:  462 ( 0.05 %) Train loss:  0.2879989743232727  Valid loss:  0.5138953924179077\n",
      "Epoch:  465 ( 0.05 %) Train loss:  0.3485211133956909  Valid loss:  0.46123406291007996\n",
      "Epoch:  468 ( 0.05 %) Train loss:  0.30781474709510803  Valid loss:  0.47000548243522644\n",
      "Epoch:  471 ( 0.05 %) Train loss:  0.30794021487236023  Valid loss:  0.4722943902015686\n",
      "Epoch:  474 ( 0.05 %) Train loss:  0.28909075260162354  Valid loss:  0.4786926209926605\n",
      "Epoch:  477 ( 0.05 %) Train loss:  0.3333856463432312  Valid loss:  0.5069752335548401\n",
      "Epoch:  480 ( 0.05 %) Train loss:  0.30367928743362427  Valid loss:  0.4900500774383545\n",
      "Epoch:  483 ( 0.05 %) Train loss:  0.30209603905677795  Valid loss:  0.5005123615264893\n",
      "Epoch:  486 ( 0.05 %) Train loss:  0.27011242508888245  Valid loss:  0.46247032284736633\n",
      "Epoch:  489 ( 0.05 %) Train loss:  0.25798913836479187  Valid loss:  0.5110255479812622\n",
      "Epoch:  492 ( 0.05 %) Train loss:  0.26446664333343506  Valid loss:  0.4930415153503418\n",
      "Epoch:  495 ( 0.05 %) Train loss:  0.26386013627052307  Valid loss:  0.5737801790237427\n",
      "Epoch:  498 ( 0.05 %) Train loss:  0.25861433148384094  Valid loss:  0.4614354074001312\n",
      "Epoch:  501 ( 0.05 %) Train loss:  0.32362622022628784  Valid loss:  0.4659014642238617\n",
      "Epoch:  504 ( 0.05 %) Train loss:  0.2442755103111267  Valid loss:  0.4520839750766754\n",
      "Epoch:  507 ( 0.05 %) Train loss:  0.26883038878440857  Valid loss:  0.4872848391532898\n",
      "Epoch:  510 ( 0.05 %) Train loss:  0.3226661682128906  Valid loss:  0.47108304500579834\n",
      "Epoch:  513 ( 0.05 %) Train loss:  0.291647344827652  Valid loss:  0.48550066351890564\n",
      "Epoch:  516 ( 0.05 %) Train loss:  0.24460965394973755  Valid loss:  0.441222220659256\n",
      "Epoch:  519 ( 0.05 %) Train loss:  0.26740938425064087  Valid loss:  0.42704272270202637\n",
      "Epoch:  522 ( 0.05 %) Train loss:  0.28040799498558044  Valid loss:  0.41457605361938477\n",
      "Epoch:  525 ( 0.05 %) Train loss:  0.2754714787006378  Valid loss:  0.39987698197364807\n",
      "Epoch:  528 ( 0.05 %) Train loss:  0.26482322812080383  Valid loss:  0.4317247271537781\n",
      "Epoch:  531 ( 0.05 %) Train loss:  0.237620010972023  Valid loss:  0.45200204849243164\n",
      "Epoch:  534 ( 0.05 %) Train loss:  0.25077059864997864  Valid loss:  0.46134623885154724\n",
      "Epoch:  537 ( 0.05 %) Train loss:  0.26532554626464844  Valid loss:  0.4666208326816559\n",
      "Epoch:  540 ( 0.05 %) Train loss:  0.2722862660884857  Valid loss:  0.483670711517334\n",
      "Epoch:  543 ( 0.05 %) Train loss:  0.2988617718219757  Valid loss:  0.4727615416049957\n",
      "Epoch:  546 ( 0.05 %) Train loss:  0.27398329973220825  Valid loss:  0.43116042017936707\n",
      "Epoch:  549 ( 0.05 %) Train loss:  0.2452700138092041  Valid loss:  0.41566339135169983\n",
      "Epoch:  552 ( 0.06 %) Train loss:  0.24820682406425476  Valid loss:  0.406343549489975\n",
      "Epoch:  555 ( 0.06 %) Train loss:  0.2634727656841278  Valid loss:  0.4150674641132355\n",
      "Epoch:  558 ( 0.06 %) Train loss:  0.25020548701286316  Valid loss:  0.5359766483306885\n",
      "Epoch:  561 ( 0.06 %) Train loss:  0.257382333278656  Valid loss:  0.47301173210144043\n",
      "Epoch:  564 ( 0.06 %) Train loss:  0.27218344807624817  Valid loss:  0.47768011689186096\n",
      "Epoch:  567 ( 0.06 %) Train loss:  0.24666336178779602  Valid loss:  0.4570412039756775\n",
      "Epoch:  570 ( 0.06 %) Train loss:  0.29465746879577637  Valid loss:  0.47025230526924133\n",
      "Epoch:  573 ( 0.06 %) Train loss:  0.2696908712387085  Valid loss:  0.4361303150653839\n",
      "Epoch:  576 ( 0.06 %) Train loss:  0.27634114027023315  Valid loss:  0.4226321578025818\n",
      "Epoch:  579 ( 0.06 %) Train loss:  0.24348925054073334  Valid loss:  0.4501596689224243\n",
      "Epoch:  582 ( 0.06 %) Train loss:  0.26634716987609863  Valid loss:  0.46627068519592285\n",
      "Epoch:  585 ( 0.06 %) Train loss:  0.24474114179611206  Valid loss:  0.48806387186050415\n",
      "Epoch:  588 ( 0.06 %) Train loss:  0.2920832633972168  Valid loss:  0.4654221832752228\n",
      "Epoch:  591 ( 0.06 %) Train loss:  0.257506787776947  Valid loss:  0.4530418813228607\n",
      "Epoch:  594 ( 0.06 %) Train loss:  0.2412358969449997  Valid loss:  0.45507219433784485\n",
      "Epoch:  597 ( 0.06 %) Train loss:  0.24030612409114838  Valid loss:  0.4149772822856903\n",
      "Epoch:  600 ( 0.06 %) Train loss:  0.26951831579208374  Valid loss:  0.4234180450439453\n",
      "Epoch:  603 ( 0.06 %) Train loss:  0.23176147043704987  Valid loss:  0.43564507365226746\n",
      "Epoch:  606 ( 0.06 %) Train loss:  0.22990617156028748  Valid loss:  0.43140503764152527\n",
      "Epoch:  609 ( 0.06 %) Train loss:  0.2366354763507843  Valid loss:  0.427351176738739\n",
      "Epoch:  612 ( 0.06 %) Train loss:  0.2316928207874298  Valid loss:  0.4369700849056244\n",
      "Epoch:  615 ( 0.06 %) Train loss:  0.2412956953048706  Valid loss:  0.42736950516700745\n",
      "Epoch:  618 ( 0.06 %) Train loss:  0.26812276244163513  Valid loss:  0.443289577960968\n",
      "Epoch:  621 ( 0.06 %) Train loss:  0.23143669962882996  Valid loss:  0.41816622018814087\n",
      "Epoch:  624 ( 0.06 %) Train loss:  0.22074145078659058  Valid loss:  0.45379525423049927\n",
      "Epoch:  627 ( 0.06 %) Train loss:  0.2510029971599579  Valid loss:  0.43259552121162415\n",
      "Epoch:  630 ( 0.06 %) Train loss:  0.24045208096504211  Valid loss:  0.43879109621047974\n",
      "Epoch:  633 ( 0.06 %) Train loss:  0.24114741384983063  Valid loss:  0.4080738425254822\n",
      "Epoch:  636 ( 0.06 %) Train loss:  0.2448706477880478  Valid loss:  0.38571739196777344\n",
      "Epoch:  639 ( 0.06 %) Train loss:  0.24809427559375763  Valid loss:  0.3947473466396332\n",
      "Epoch:  642 ( 0.06 %) Train loss:  0.2494085431098938  Valid loss:  0.436798095703125\n",
      "Epoch:  645 ( 0.06 %) Train loss:  0.2440022975206375  Valid loss:  0.44509270787239075\n",
      "Epoch:  648 ( 0.06 %) Train loss:  0.259768009185791  Valid loss:  0.4914116859436035\n",
      "Epoch:  651 ( 0.07 %) Train loss:  0.2828691899776459  Valid loss:  0.40649259090423584\n",
      "Epoch:  654 ( 0.07 %) Train loss:  0.2596319019794464  Valid loss:  0.452155202627182\n",
      "Epoch:  657 ( 0.07 %) Train loss:  0.2251802682876587  Valid loss:  0.3817116320133209\n"
     ]
    }
   ],
   "source": [
    "mynet = tc.train_valid_loop(batch_size=3000, Nepochs=1000000,\n",
    "                         learning_rate=1e-3, save_model_interval=50,\n",
    "                         my_seed=410, add_name_str='single_lior')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
